{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "In this demo, we are going to use LangGraph to create a simple chat agent using the so called \"prebuilt agents\" framework.  We'll start with the LangGraph code to create and run the agent without Mindlytics. After that runs, we'll integrate Mindlytics to instrument the application to get analytics.  \n",
    "\n",
    "For this demo, in addition to an `OPENAI_API_KEY`, you will need a Mindlytics api key and project id.  These can be sent in environment variables; `MLSDK_API_KEY` and `MLSDK_PROJECT_ID`.  To run this notebook from the command line, you can\n",
    "\n",
    "```sh\n",
    "OPENAI_API_KEY=xxx MLSDK_API_KEY=yyy MLSDK_PROJECT_ID=zzz poetry run jupyter lab examples/langchain/chatbot.ipynb\n",
    "```\n",
    "\n",
    "Lets start out with the required imports and checks for environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from typing import List\n",
    "from langchain_core.messages import AIMessageChunk\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import InMemorySaver  # for chat history\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "import json\n",
    "import rich\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Error: OPENAI_API_KEY environment variable not set.\")\n",
    "    print(\"Please set your OpenAI API key:\")\n",
    "    print(\"export OPENAI_API_KEY='your-api-key-here'\")\n",
    "    sys.exit(1)\n",
    "\n",
    "if not (os.getenv(\"MLSDK_API_KEY\") and os.getenv(\"MLSDK_PROJECT_ID\") ):\n",
    "    print(\"Error: Mindlytics environment is not set up.  The latter part of this demo will not work without them\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Lets create the LLM model, with parameters to capture tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=MODEL,\n",
    "    temperature=0.7,\n",
    "    model_kwargs={\n",
    "        \"stream_options\": {\"include_usage\": True},\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "We will create a couple of tools for the agent to use.  The first tool can look up user details based on a user's name.  The second tool can look up order details based on an order number.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "async def find_user(name: str) -> str:\n",
    "    \"\"\"Find user details by name.\"\"\"\n",
    "\n",
    "    # simulate a little time\n",
    "    await asyncio.sleep(2)\n",
    "    \n",
    "    # We would do some sort of database lookup here, but for this demo ...\n",
    "    match = {\n",
    "        \"name\": \"Princess Leia\",\n",
    "        \"email\": \"princess.leia@alderaan.gal\",\n",
    "        \"address\": \"Princess Leia Organa\\nRoyal Palace\\nCity of Aldera\\nPlanet Alderaan\\nCore Worlds, Galactic Republic\"\n",
    "    }\n",
    "\n",
    "    return json.dumps(match, indent=2)\n",
    "\n",
    "@tool\n",
    "async def lookup_order(order: str) -> str:\n",
    "    \"\"\"Look up an order by order id.\"\"\"\n",
    "\n",
    "    # simulate a little time\n",
    "    await asyncio.sleep(2)\n",
    "\n",
    "    # We would do some sort of database lookup here, but for this demo ...\n",
    "    match = {\n",
    "        \"order\": order,\n",
    "        \"purchased_on\": \"2024-04-25T06:34:54\"\n",
    "    }\n",
    "\n",
    "    return json.dumps(match, indent=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Create the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver() # manage chat history\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[find_user, lookup_order],\n",
    "    checkpointer=checkpointer,\n",
    "    prompt=\"You are the customer service agent at the Galactic Toys and Trinkets store.  To process returns, you can search for user information using supplied tools.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Now lets run the agent with a canned set of user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our canned user input\n",
    "user_messages = [\n",
    "    \"I would like to return a hair bun scrunchy.  It is too small for me!\",\n",
    "    \"My name sir, is Princess Leia of Alderaan!\",\n",
    "    \"Of course I want to proceed!\",\n",
    "    \"My order number is 19-BBY.\",\n",
    "    \"Never mind.  We're done here!\",\n",
    "    \"Goodbye sir.\",\n",
    "]\n",
    "\n",
    "# This state is required for chat history (thread_id)\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"1\",\n",
    "    }\n",
    "}\n",
    "\n",
    "for user_message in user_messages:\n",
    "    print(f\"User: {user_message}\")\n",
    "    print(\"Assistant: \", end=\"\", flush=True)\n",
    "    async for chunk in agent.astream(\n",
    "        {\n",
    "            \"messages\": user_message\n",
    "        },\n",
    "        stream_mode=[\"messages\"],\n",
    "        config=config\n",
    "    ):\n",
    "        mode = chunk[0]\n",
    "        if mode == \"messages\":\n",
    "            data: AIMessageChunk = chunk[1][0]\n",
    "            if isinstance(data, AIMessageChunk) and len(data.content) > 0:\n",
    "                # Stream a token to the screen\n",
    "                print(data.content, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Now we'd like to integrate Mindlytics into this application.  We'd like to capture three things\n",
    "\n",
    "* User identification - When we learn about the initially anonymous user, identify this user to Mindlytics\n",
    "* Conversational turns - Report user/assisant turns\n",
    "* Function calls - Report function calls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Lets import the Mindlytics stuff we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlsdk import Client, Session, MLEvent\n",
    "from mlsdk.helpers.langgraph import MLPostModellHook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Lets redefine the `find_user` tool so that when a user record is found in the user database, we can identify this user to Mindlytics.  This user will replace the initially anonymous user that began the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "async def find_user(\n",
    "    name: str, \n",
    "    config: RunnableConfig # Add LangGraph annotation to get access to Session\n",
    ") -> str:\n",
    "    \"\"\"Find user details by name.\"\"\"\n",
    "\n",
    "    # simulate a little time\n",
    "    await asyncio.sleep(2)\n",
    "    \n",
    "    # We would do some sort of database lookup here, but for this demo ...\n",
    "    match = {\n",
    "        \"name\": \"Princess Leia\",\n",
    "        \"email\": \"princess.leia@alderaan.gal\",\n",
    "        \"address\": \"Princess Leia Organa\\nRoyal Palace\\nCity of Aldera\\nPlanet Alderaan\\nCore Worlds, Galactic Republic\"\n",
    "    }\n",
    "\n",
    "    # Send the identification to Mindlytics\n",
    "    session: Session = config[\"configurable\"].get(\"session\")\n",
    "    if session is not None:\n",
    "        await session.user_identify(\n",
    "            id=match[\"email\"],\n",
    "            traits=match,\n",
    "        )\n",
    "\n",
    "    return json.dumps(match, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Now lets re-create the agent so it uses the new `find_user` tool, and we will also add the `MLPostModelHook` Mindlytics helper.  This helper will do all of the work to send conversation turns to Mindlytics.  The helper will also track tool use and send that information to Mindlytics as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver() # manage chat history\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[find_user, lookup_order],\n",
    "    checkpointer=checkpointer,\n",
    "    prompt=\"You are the customer service agent at the Galactic Toys and Trinkets store.  To process returns, you can search for user information using supplied tools.\",\n",
    "    post_model_hook=MLPostModellHook(model_name=model.model_name),  # ADD THE MINDLYTICS POST HOOK HERE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Now we will create the Mindlytics session and invoke the agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The client constructor will read MLSDK_API_KEY and MLSDK_PROJECT_ID \n",
    "ml_client = Client()\n",
    "\n",
    "# Capture any Mindlytic communication errors\n",
    "ml_errors: List[Exception]  = []\n",
    "async def on_error(error: Exception):\n",
    "    # Handle Mindlytics errors here\n",
    "    ml_errors.append(error)\n",
    "\n",
    "# Capture Mindlytics Events\n",
    "ml_events: List[MLEvent] = []\n",
    "async def on_event(event: MLEvent):\n",
    "    # Handle Mindlytics events here\n",
    "    ml_events.append(event)\n",
    "\n",
    "# Create the session.  We don't know who the user is at first, so pass in our device id\n",
    "# Make a device_id\n",
    "import uuid\n",
    "mac = uuid.getnode()\n",
    "device_id = f\"{mac:012x}\"\n",
    "\n",
    "session = ml_client.create_session(\n",
    "    session_id=str(uuid.uuid4()),\n",
    "    conversation_id=str(uuid.uuid4()),\n",
    "    device_id=device_id,\n",
    "    on_error=on_error,\n",
    "    on_event=on_event,\n",
    ")\n",
    "\n",
    "# This state will be available to function calls, and other parts of the agent framework\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"session\": session,\n",
    "        \"thread_id\": session.session_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Our canned user input\n",
    "user_messages = [\n",
    "    \"I would like to return a hair bun scrunchy.  It is too small for me!\",\n",
    "    \"My name sir, is Princess Leia of Alderaan!\",\n",
    "    \"Of course I want to proceed!\",\n",
    "    \"My order number is 19-BBY.\",\n",
    "    \"Never mind.  We're done here!\",\n",
    "    \"Goodbye sir.\",\n",
    "]\n",
    "\n",
    "for user_message in user_messages:\n",
    "    print(f\"User: {user_message}\")\n",
    "    print(\"Assistant: \", end=\"\", flush=True)\n",
    "    async for chunk in agent.astream(\n",
    "        {\n",
    "            \"messages\": user_message\n",
    "        },\n",
    "        stream_mode=[\"messages\"],\n",
    "        config=config\n",
    "    ):\n",
    "        mode = chunk[0]\n",
    "        if mode == \"messages\":\n",
    "            data: AIMessageChunk = chunk[1][0]\n",
    "            if isinstance(data, AIMessageChunk) and len(data.content) > 0:\n",
    "                # Stream a token to the screen\n",
    "                print(data.content, end=\"\", flush=True)\n",
    "                \n",
    "    print(\"\\n\")\n",
    "\n",
    "await session.end_session()\n",
    "await session.flush()\n",
    "print(\"ALL DONE!\")\n",
    "\n",
    "# The session is complete.  WAIT UNTIL YOU SEE THIS \"ALL DONE\" TO PROCEED WITH THE DEMO!!!\n",
    "\n",
    "print(f\"We received {len(ml_events)} events and {len(ml_errors)} errors.\")\n",
    "if len(ml_errors) > 0:\n",
    "    print()\n",
    "    print(\"Mindlytics Errors:\")\n",
    "    for error in ml_errors:\n",
    "        print(\"------------------------------------------------\")\n",
    "        print(error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Lets look at a summary of events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in ml_events:\n",
    "    print(event.event)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "You should see some events. You should see a \"Session Started\" at the beginning and a \"Session Ended\" at the end. Within the session there should be a \"Conversation Started\"/\"Conversation Ended\" pair, and within the conversation you will see a number of events that were captured. Every event contains a lot of detail. Lets take a detailed look at the \"Conversation Summary\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = next((event for event in ml_events if event.event == 'Conversation Summary'), None)\n",
    "if summary is None:\n",
    "    print(\"Cannot find the Conversation Summary event!\")\n",
    "\n",
    "for key, value in summary.properties.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "You can see some statistics about the conversation, the summary and the sentiment of the user. Because we tracked token usage, we have a final cost calculation based on the MODEL you used to run the conversation.\n",
    "\n",
    "If you want to continue this demo by examining some of the other events in detail, here is a helper function to display one or more events by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_events(event_name):\n",
    "    for event in ml_events:\n",
    "        if event.event == event_name:\n",
    "            print()\n",
    "            print(f\"Event: {event.event}\")\n",
    "            print(f\"  timestamp: {event.timestamp}\")\n",
    "            for prop in [\"session_id\", \"conversation_id\", \"event_id\", \"origin_event_id\"]:\n",
    "                if hasattr(event, prop):\n",
    "                    print(f\"  {prop}: {getattr(event, prop)}\")\n",
    "            if hasattr(event, \"properties\"):\n",
    "                print(\"  properties:\")\n",
    "                for key, value in event.properties.items():\n",
    "                    print(f\"    {key}: {value}\")\n",
    "            if hasattr(event, \"user_traits\"):\n",
    "                print(\"  user_traits:\")\n",
    "                for key, value in event.user_traits.items():\n",
    "                    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_events(\"Conversation Function\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mindlytics Python SDK",
   "language": "python",
   "name": "mindlytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
