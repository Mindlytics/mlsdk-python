{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "This example uses LangGraph to create a simeple agent with some tools.  It demonstrates Mindlytics user identification during a conversation.  It also shows how the Mindlytics session can be passed around in LangGraph.\n",
    "\n",
    "We are going to implement a simple customer service assistant.  The conversation will start out without the assistant knowning the user, so a Mindlytics session will be started with a \"device id\".  During the conversation the assistant will need to determine the user and will call a tool to search a company database of users to obtain the user.  This tool will then call the Mindlytics sdk to identify the user in this conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import uuid\n",
    "from typing import Any\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import ChatOpenAI                # we are using openai\n",
    "from langchain_core.messages import AIMessageChunk     # to detect assistant responses\n",
    "from langgraph.prebuilt import create_react_agent      # pre-built agent\n",
    "from langchain_core.tools import tool                  # we are going to define a tool\n",
    "from langchain_core.runnables import RunnableConfig    # for accessing ML session in tools\n",
    "from langgraph.checkpoint.memory import InMemorySaver  # for chat history\n",
    "# Mindlytics imports needed for this demo\n",
    "from mlsdk import Client, Session, MLEvent, TokenBasedCost\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Error: OPENAI_API_KEY environment variable not set.\")\n",
    "    print(\"Please set your OpenAI API key:\")\n",
    "    print(\"export OPENAI_API_KEY='your-api-key-here'\")\n",
    "    sys.exit(1)\n",
    "\n",
    "if not (os.getenv(\"MLSDK_API_KEY\") and os.getenv(\"MLSDK_PROJECT_ID\") ):\n",
    "    print(\"Error: Mindlytics environment is not set up.  The latter part of this demo will not work without them\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Lets create the LLM model, with parameters to capture tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=MODEL,\n",
    "    temperature=0.7,\n",
    "    model_kwargs={\n",
    "        \"stream_options\": {\"include_usage\": True},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "We need a tool to search the company database for a user record.  This will be called by the agent when a user needs to be identified.  In this tool we will identify this user to Mindlytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User(BaseModel):\n",
    "    email: str\n",
    "    name: str\n",
    "    address: str\n",
    "    \n",
    "@tool(\"find_user_information\", parse_docstring=True)\n",
    "async def find_user_information(\n",
    "    name_or_email: str,\n",
    "    config: RunnableConfig,\n",
    ") -> User:\n",
    "    \"\"\"Given a user name or an email address, return a User record for that user.\n",
    "\n",
    "    Args:\n",
    "        name_or_email: A user name or an email address\n",
    "\n",
    "    Returns:\n",
    "        User\n",
    "    \"\"\"\n",
    "    # We would do a database lookup of course, but for this demo ...\n",
    "    match = User(\n",
    "        name=\"Princess Leia\",\n",
    "        email=\"princess.leia@alderaan.gal\",\n",
    "        address=\"Princess Leia Organa\\nRoyal Palace\\nCity of Aldera\\nPlanet Alderaan\\nCore Worlds, Galactic Republic\"\n",
    "    )\n",
    "\n",
    "    # Send the identification to Mindlytics\n",
    "    session: Session = config[\"configurable\"].get(\"session\")\n",
    "    if session is not None:\n",
    "        await session.user_identify(\n",
    "            id=match.email,\n",
    "            traits=match.model_dump(exclude_none=True)\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(\"Could not find ML session in tool context!\")\n",
    "\n",
    "    return match\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Create the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver() # manage chat history\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[find_user_information],\n",
    "    checkpointer=checkpointer,\n",
    "    prompt=\"You are the customer service agent at the Galactic Toys and Trinkets store.  To process returns, you can search for user information using supplied tools.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Create a device id for this platform and initialize the Mindlytics sdk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a device_id\n",
    "mac = uuid.getnode()\n",
    "device_id = f\"{mac:012x}\"\n",
    "\n",
    "# The client constructor will read MLSDK_API_KEY and MLSDK_PROJECT_ID \n",
    "ml_client = Client()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "This function will be called to process chunks as they are streamed from the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_chunk(\n",
    "    session: Session,\n",
    "    user_message: str,\n",
    "    mode: str,\n",
    "    chunk: Any,\n",
    ") -> None:\n",
    "    if mode == \"messages\":\n",
    "        data = chunk[0]\n",
    "        if isinstance(data, AIMessageChunk) and len(data.content) > 0:\n",
    "            print(data.content, end=\"\", flush=True)\n",
    "    elif mode == \"updates\":\n",
    "        data = chunk\n",
    "        if data.get(\"agent\") is not None:\n",
    "            message = data[\"agent\"][\"messages\"][0]\n",
    "            if message.response_metadata.get(\"finish_reason\") == \"stop\":\n",
    "                assistant_message = message.content\n",
    "                usage = {\n",
    "                    \"prompt_tokens\": 0,\n",
    "                    \"completion_tokens\": 0,\n",
    "                    \"model\": MODEL,\n",
    "                }\n",
    "                usage_metadata = getattr(message, \"usage_metadata\", None)\n",
    "                if usage_metadata is not None:\n",
    "                    usage = {\n",
    "                        \"prompt_tokens\": usage_metadata.get(\"input_tokens\", 0),\n",
    "                        \"completion_tokens\": usage_metadata.get(\"output_tokens\", 0),\n",
    "                        \"model\": MODEL,\n",
    "                    }\n",
    "                await session.track_conversation_turn(\n",
    "                    user=user_message,\n",
    "                    assistant=assistant_message,\n",
    "                    usage=TokenBasedCost(**usage),\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Now we will create the Mindlytics session context and invoke the agent.  The `user_messages` are a list of user statements to the conversation.  The LLM could behave in a variety of ways, so the user messages might not make a lot of sense after the first couple, but it is assusing to see what the LLM comes up with.  The important part is that the LLM will call our tool to identify the princess, which will identity Leia as the user of this conversation on this device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the context.  We don't know who the user is at first, so pass in our device id\n",
    "session_context = ml_client.create_session(\n",
    "    device_id=device_id,\n",
    ")\n",
    "\n",
    "# Not used in this demo, but if you want to modify the loop and prompt for manual input, then\n",
    "# you could use this function like\n",
    "#\n",
    "#  user_message = await prompt(\"Princess Leia?:\")\n",
    "#\n",
    "async def prompt(prompt_text: str) -> str:\n",
    "    loop = asyncio.get_running_loop()\n",
    "    return await loop.run_in_executor(None, input, prompt_text)\n",
    "\n",
    "# Start the session\n",
    "async with session_context as session:\n",
    "    # This state will be available to function calls, and other parts of the agent framework\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"session\": session,\n",
    "            \"thread_id\": session.session_id,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Our canned user input\n",
    "    user_messages = [\n",
    "        \"I would like to return a hair bun scrunchy.  It is too small for me!\",\n",
    "        \"My name sir, is Princess Leia of Alderaan!\",\n",
    "        \"Of course I want to proceed!\",\n",
    "        \"My order number is 19-BBY.\",\n",
    "        \"Never mind.  We're done here!\",\n",
    "        \"Goodbye sir.\",\n",
    "    ]\n",
    "\n",
    "    for user_message in user_messages:\n",
    "        print(f\"User: {user_message}\")\n",
    "        print(\"Assistant: \", end=\"\", flush=True)\n",
    "        async for mode, chunk in agent.astream(\n",
    "            {\n",
    "                \"messages\": user_message\n",
    "            },\n",
    "            stream_mode=[\"updates\", \"messages\"],\n",
    "            config=config\n",
    "        ):\n",
    "            # process the chunk\n",
    "            await process_chunk(\n",
    "                session=session,\n",
    "                user_message=user_message,\n",
    "                mode=mode,\n",
    "                chunk=chunk,\n",
    "            )\n",
    "            \n",
    "        print(\"\\n\")\n",
    "\n",
    "print(\"The conversation is finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mindlytics Python SDK",
   "language": "python",
   "name": "mindlytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
